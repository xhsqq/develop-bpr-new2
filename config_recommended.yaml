# ============================================
# 推荐配置 - 基于13万样本×110万交互的实际分析
# 设计理念：Item Embedding为主 + 轻量编码器
# ============================================

# ============ 数据配置 ============
data:
  category: "beauty"
  raw_dir: "data/raw"
  processed_dir: "data/processed"
  data_dir: "data/processed"
  
  batch_size: 256                      # 大batch稳定训练
  num_workers: 4
  shuffle: true
  pin_memory: true
  
  max_seq_length: 50
  min_seq_length: 2
  min_interactions: 5

# ============ 模型架构 - 推荐设计 ============
model:
  # ⭐⭐⭐ 核心设计理念：
  # 1. Item Embedding是核心（占35%参数，通过110万交互训练）
  # 2. 编码器要轻量（占65%参数，通过13万序列训练）
  # 3. 总参数控制在1.2-1.5M（平衡容量和过拟合）
  
  # 多模态维度
  modality_dims:
    text: 768
    image: 2048
  
  # ⭐⭐⭐ 关键1：投影层（轻量但不极端）
  modality_proj_dims:
    text: 96                           # 768 → 96 (减少87%)
    image: 192                         # 2048 → 192 (减少91%)
    # 总维度：2816 → 288（减少90%）
    # 投影层参数：768×96 + 2048×192 = 467K
  
  # ⭐⭐⭐ 关键2：Item Embedding（这是核心！）
  item_embed_dim: 64                   # 64维（12K物品 × 64 = 770K）
                                       # 这770K参数由110万交互训练，充分！
  
  # 解耦表征（轻量化）
  disentangled_dim: 32                 # 32维（不要太小）
  num_disentangled_dims: 3             # 3个维度
                                       # 总输出：32×3 = 96维
  
  disentangled:
    encoder_hidden_dims: [192, 96]     # 渐进降维：288 → 192 → 96 → 32
    vae_reduction_ratio: 0.5
    attention_dim: 48
  
  # 序列编码（适度容量）
  hidden_dim: 80                       # GRU隐藏层80维
                                       # 输入：96+64=160维
                                       # 输出：80×2=160维（双向）
  
  sequence_encoder:
    num_layers: 2
    bidirectional: true
    dropout: 0.2
  
  # 量子编码器（简化）
  quantum_version: "simplified"
  num_interests: 3                     # 3个兴趣
  quantum_state_dim: 32
  use_quantum_computing: false
  
  quantum:
    attention_heads: 2
    interference_init_std: 0.01
    phase_range: "pi"
    init_scale: "sqrt"
  
  # 因果推断（轻量）
  causal:
    scm_hidden_dim: 40
    intervention_types:
      - "function_to_mean"
      - "aesthetics_shift"
      - "emotion_swap"
    target_ite_magnitude: 0.3
    uncertainty_dropout: 0.3
  
  dropout: 0.3                         # ⭐ 强正则化（防止编码器过拟合）

# ============ 损失权重配置 ============
loss:
  # 损失权重 (⭐ 修复：增加权重以平衡与BPR损失的比例)
  alpha_recon: 0.1                     # 重构损失（从0.01增加到0.1）
  alpha_causal: 0.05                   # 因果损失（从0.005增加到0.05）
  alpha_diversity: 0.01                # 多样性损失（从0.002增加到0.01）
  
  # KL正则化
  beta: 0.1                            # ⭐ 较强KL正则（防止VAE坍塌）
  gamma: 0.0
  use_kl_loss: true
  use_independence_loss: false
  
  quantum_weights:
    diversity: 0.7
  
  causal_weights:
    magnitude: 1.0

# ============ 训练配置 ============
training:
  batch_size: 256
  num_epochs: 80
  learning_rate: 0.001
  weight_decay: 0.001                  # ⭐ 强权重衰减
  
  # 学习率调度
  lr_scheduler: "cosine"
  lr_warmup_epochs: 8
  lr_min: 0.00005
  
  # KL退火
  kl_anneal_epochs: 20
  
  # 优化器
  optimizer: "adamw"
  grad_clip: 1.0
  
  # 早停
  early_stopping:
    patience: 12
    min_delta: 0.0003
  
  save_every: 5
  checkpoint_dir: "checkpoints"

# ============ 评估配置 ============
evaluation:
  top_k: [5, 10, 20]
  metrics:
    - "recall"
    - "ndcg"
    - "hit_rate"
    - "mrr"
  eval_every: 1
  filter_train_items: true
  test_batch_size: 512

# ============ 消融实验配置 ============
ablation:
  enable_disentangled: true
  enable_quantum: true
  enable_causal: true

# ============ 高级配置 ============
advanced:
  temperature: 0.2                     # ⭐ 修复：降低温度以增强判别性（从0.5到0.2）
  num_negatives: 500                   # ⭐ 修复：增加负采样以减少训练-评估差距（从100到500）
  use_config_temperature: true
  use_config_negatives: true
  
  num_mc_samples: 10
  use_config_mc_samples: true
  num_ensembles: 3
  target_ite: 0.3
  
  quantum_measurement_samples: 1

# ============ 硬件配置 ============
device:
  use_gpu: true
  gpu_ids: [0]
  mixed_precision: false

# ============ 随机种子 ============
seed: 42

# ============ 日志配置 ============
logging:
  use_tensorboard: true
  log_dir: "runs"
  log_every: 100
  visualize_attention: false
  visualize_quantum: false

# ============ 实验信息 ============
experiment:
  name: "recommended-multimodal-rec"
  tags:
    - "recommended-architecture"
    - "item-embedding-centric"
    - "13w-samples-110w-interactions"
  notes: |
    ⭐ 推荐架构设计
    
    核心设计理念：
    
    1. 重新理解训练样本：
       - 不是13万序列，而是110万+交互
       - Item Embedding由交互训练，编码器由序列训练
       - 分开评估，不能混为一谈
    
    2. 参数分配策略：
       - Item Embedding: ~770K (35%)
         由110万交互训练，交互/参数 ≈ 1.4，充分！
       - 编码器模块: ~1M (65%)
         由13万序列训练，序列/参数 ≈ 0.13，需强正则化
    
    3. 轻量投影层：
       - Text: 768 → 96 (467K参数，比之前减少25%)
       - Image: 2048 → 192
       - 投影后总维度：288（非常紧凑）
    
    4. 强正则化策略：
       - Dropout: 0.3（高）
       - Weight Decay: 0.001（强）
       - KL Beta: 0.1（较强）
       - 负采样: 150（充分）
    
    5. 预期参数量：~1.3-1.5M
       - 比"最优配置"少30%
       - 比"当前配置"多100%（避免欠拟合）
    
    6. 为什么不用更轻量的特征提取？
       答：投影层已经很轻了（467K），继续减少会损失信息。
       真正的优化空间在于：
       - 强正则化（dropout, weight decay）
       - 充分负采样（150个）
       - 早停策略（patience=12）
    
    预期效果：
    - NDCG@10: 0.06-0.09
    - 训练稳定，不易过拟合

