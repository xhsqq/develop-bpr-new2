"""
æ¸è¿›å¼å¤šæ¨¡æ€æ¨èå™¨
æ”¯æŒé€šè¿‡é…ç½®é€æ­¥å¯ç”¨åŠŸèƒ½ï¼šBaseline â†’ +è§£è€¦ â†’ +é‡å­ â†’ +å› æœ

è®¾è®¡ç†å¿µï¼š
- æ‰€æœ‰åŠŸèƒ½å…³é—­æ—¶ = Baseline
- é€æ­¥æ‰“å¼€åŠŸèƒ½ï¼Œè§‚å¯Ÿå¢ç›Š
- æ¨¡å—åŒ–è®¾è®¡ï¼Œä¾¿äºæ¶ˆèå®éªŒ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Optional, Tuple

try:
    from .disentangled_representation import DisentangledRepresentation
    from .quantum_inspired_encoder import QuantumInspiredMultiInterestEncoder
    from .causal_inference import CausalInferenceModule
    from utils.losses import BPRLoss
except ImportError:
    # å½“ä½œä¸ºè„šæœ¬ç›´æ¥è¿è¡Œæ—¶
    import sys
    import os
    sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from models.disentangled_representation import DisentangledRepresentation
    from models.quantum_inspired_encoder import QuantumInspiredMultiInterestEncoder
    from models.causal_inference import CausalInferenceModule
    from utils.losses import BPRLoss


class ProgressiveMultimodalRecommender(nn.Module):
    """
    æ¸è¿›å¼å¤šæ¨¡æ€æ¨èå™¨
    
    é…ç½®ç¤ºä¾‹ï¼š
    - Stage 0 (Baseline): enable_disentangled=False, enable_quantum=False, enable_causal=False
    - Stage 1 (+è§£è€¦): enable_disentangled=True, enable_quantum=False, enable_causal=False
    - Stage 2 (+é‡å­): enable_disentangled=True, enable_quantum=True, enable_causal=False
    - Stage 3 (å®Œæ•´): enable_disentangled=True, enable_quantum=True, enable_causal=True
    """
    
    def __init__(
        self,
        # åŸºç¡€é…ç½®
        text_dim: int = 768,
        image_dim: int = 2048,
        item_embed_dim: int = 128,
        hidden_dim: int = 256,
        num_items: int = 10000,
        
        # åŠŸèƒ½å¼€å…³ â­â­â­
        enable_disentangled: bool = False,  # æ˜¯å¦å¯ç”¨è§£è€¦æ¨¡å—
        enable_quantum: bool = False,       # æ˜¯å¦å¯ç”¨é‡å­ç¼–ç å™¨
        enable_causal: bool = False,        # æ˜¯å¦å¯ç”¨å› æœæ¨æ–­
        
        # è§£è€¦é…ç½®ï¼ˆä»…å½“enable_disentangled=Trueæ—¶ç”Ÿæ•ˆï¼‰
        disentangled_dim: int = 64,
        num_disentangled_dims: int = 3,
        
        # é‡å­é…ç½®ï¼ˆä»…å½“enable_quantum=Trueæ—¶ç”Ÿæ•ˆï¼‰
        num_interests: int = 4,
        quantum_state_dim: int = 128,
        
        # å› æœé…ç½®ï¼ˆä»…å½“enable_causal=Trueæ—¶ç”Ÿæ•ˆï¼‰
        num_ensembles: int = 3,
        num_mc_samples: int = 10,
        target_ite: float = 0.3,
        
        # æŸå¤±æƒé‡
        alpha_recon: float = 0.01,
        alpha_causal: float = 0.005,
        alpha_diversity: float = 0.001,
        beta: float = 0.05,
        
        # å…¶ä»–
        dropout: float = 0.2,
        num_negatives: int = 100,
        temperature: float = 0.5,
        use_quantum_computing: bool = False
    ):
        super().__init__()
        
        self.enable_disentangled = enable_disentangled
        self.enable_quantum = enable_quantum
        self.enable_causal = enable_causal
        
        self.text_dim = text_dim
        self.image_dim = image_dim
        self.hidden_dim = hidden_dim
        self.item_embed_dim = item_embed_dim
        self.num_items = num_items
        
        # æŸå¤±æƒé‡
        self.alpha_recon = alpha_recon if enable_disentangled else 0.0
        self.alpha_causal = alpha_causal if enable_causal else 0.0
        self.alpha_diversity = alpha_diversity if enable_quantum else 0.0
        self.beta = beta if enable_disentangled else 0.0
        
        print("\n" + "="*80)
        print("ğŸ¯ æ¸è¿›å¼æ¨èå™¨é…ç½®")
        print("="*80)
        print(f"è§£è€¦æ¨¡å—: {'âœ…' if enable_disentangled else 'âŒ'}")
        print(f"é‡å­ç¼–ç å™¨: {'âœ…' if enable_quantum else 'âŒ'}")
        print(f"å› æœæ¨æ–­: {'âœ…' if enable_causal else 'âŒ'}")
        print("="*80 + "\n")
        
        # ==================== å¤šæ¨¡æ€èåˆ ====================
        
        if enable_disentangled:
            # ä½¿ç”¨è§£è€¦æ¨¡å—
            self.disentangled_module = DisentangledRepresentation(
                input_dims={'text': text_dim, 'image': image_dim},
                latent_dim=disentangled_dim,
                beta=beta
            )
            # è§£è€¦åçš„ç‰¹å¾ç»´åº¦
            fusion_dim = disentangled_dim * num_disentangled_dims
        else:
            # Baseline: ç®€å•concat
            self.multimodal_proj = nn.Sequential(
                nn.Linear(text_dim + image_dim, hidden_dim),
                nn.LayerNorm(hidden_dim),
                nn.GELU(),
                nn.Dropout(dropout)
            )
            fusion_dim = hidden_dim
        
        # ==================== Item Embedding ====================
        
        self.item_embedding = nn.Embedding(
            num_items + 1,
            item_embed_dim,
            padding_idx=0
        )
        
        # ==================== åºåˆ—ç¼–ç å™¨ ====================
        
        # è¾“å…¥ç»´åº¦ = fusion_dim + item_embed_dim
        sequence_input_dim = fusion_dim + item_embed_dim
        
        self.sequence_encoder = nn.GRU(
            input_size=sequence_input_dim,
            hidden_size=hidden_dim,
            num_layers=1,
            batch_first=True,
            dropout=0.0,
            bidirectional=True
        )
        
        # GRUè¾“å‡ºæŠ•å½±
        self.sequence_proj = nn.Linear(hidden_dim * 2, sequence_input_dim)
        
        # ==================== é‡å­ç¼–ç å™¨ï¼ˆå¯é€‰ï¼‰====================
        
        if enable_quantum:
            self.quantum_encoder = QuantumInspiredMultiInterestEncoder(
                input_dim=sequence_input_dim,
                num_interests=num_interests,
                qubit_dim=quantum_state_dim // 2,
                output_dim=item_embed_dim,
                hidden_dim=hidden_dim,
                use_quantum_computing=use_quantum_computing
            )
            user_repr_dim = item_embed_dim
        else:
            # ç›´æ¥æŠ•å½±åˆ°itemç©ºé—´
            self.user_proj = nn.Linear(sequence_input_dim, item_embed_dim)
            user_repr_dim = item_embed_dim
        
        # ==================== å› æœæ¨æ–­ï¼ˆå¯é€‰ï¼‰====================
        
        if enable_causal:
            self.causal_module = CausalInferenceModule(
                disentangled_dim=disentangled_dim if enable_disentangled else hidden_dim,
                num_dimensions=num_disentangled_dims if enable_disentangled else 1,
                hidden_dim=hidden_dim,
                num_ensembles=num_ensembles,
                feature_dim=sequence_input_dim
            )
            self.num_mc_samples = num_mc_samples
            self.target_ite = target_ite
        
        # ==================== æ‰“åˆ† ====================
        
        self.item_bias = nn.Parameter(torch.zeros(num_items + 1))
        self.register_buffer('temperature', torch.tensor(temperature))
        
        # ==================== æŸå¤±å‡½æ•° ====================
        
        self.bpr_loss_fn = BPRLoss()
        
        # åˆå§‹åŒ–
        self._init_weights()
    
    def _init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.zeros_(module.bias)
            elif isinstance(module, nn.Embedding):
                nn.init.normal_(module.weight, mean=0.0, std=0.02)
                if module.padding_idx is not None:
                    module.weight.data[module.padding_idx].zero_()
    
    def forward(
        self,
        item_ids: torch.Tensor,
        multimodal_features: Dict[str, torch.Tensor],
        seq_lengths: torch.Tensor,
        target_items: Optional[torch.Tensor] = None,
        candidate_items: Optional[torch.Tensor] = None,
        return_loss: bool = True
    ) -> Dict[str, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            item_ids: (batch, seq_len)
            multimodal_features: {'text': (batch, seq_len, 768), 'image': (batch, seq_len, 2048)}
            seq_lengths: (batch,)
            target_items: (batch,)
            candidate_items: (batch, num_cand)
            return_loss: bool
        """
        batch_size, seq_len = item_ids.shape
        device = item_ids.device
        
        # ==================== 1. å¤šæ¨¡æ€èåˆ ====================
        
        text_seq = multimodal_features['text']  # (batch, seq_len, 768)
        image_seq = multimodal_features['image']  # (batch, seq_len, 2048)
        
        if self.enable_disentangled:
            # ä½¿ç”¨è§£è€¦æ¨¡å—å¤„ç†æ¯ä¸ªæ—¶é—´æ­¥
            all_fused = []
            disentangled_losses = []
            
            for t in range(seq_len):
                multimodal_t = {
                    'text': text_seq[:, t, :],
                    'image': image_seq[:, t, :]
                }
                
                disentangled_out = self.disentangled_module(
                    multimodal_t,
                    return_loss=return_loss
                )
                
                all_fused.append(disentangled_out['z_concat'])
                
                if return_loss:
                    disentangled_losses.append(disentangled_out['loss'])
            
            fused_features = torch.stack(all_fused, dim=1)  # (batch, seq_len, fusion_dim)
            
            if return_loss:
                recon_loss = torch.stack(disentangled_losses).mean()
            else:
                recon_loss = None
        else:
            # Baseline: ç®€å•concat
            multimodal_concat = torch.cat([text_seq, image_seq], dim=-1)  # (batch, seq_len, 2816)
            fused_features = self.multimodal_proj(multimodal_concat)  # (batch, seq_len, hidden_dim)
            recon_loss = None
        
        # ==================== 2. æ‹¼æ¥Item Embedding ====================
        
        item_embeds = self.item_embedding(item_ids)  # (batch, seq_len, item_embed_dim)
        
        # æ‹¼æ¥å¤šæ¨¡æ€ç‰¹å¾å’Œitem embedding
        combined_features = torch.cat([fused_features, item_embeds], dim=-1)  # (batch, seq_len, fusion_dim + item_embed_dim)
        
        # ==================== 3. åºåˆ—ç¼–ç  ====================
        
        # Pack padded sequence
        packed = nn.utils.rnn.pack_padded_sequence(
            combined_features,
            seq_lengths.cpu(),
            batch_first=True,
            enforce_sorted=False
        )
        
        output, _ = self.sequence_encoder(packed)
        
        # Unpack
        output, _ = nn.utils.rnn.pad_packed_sequence(
            output,
            batch_first=True,
            total_length=seq_len
        )
        
        output = self.sequence_proj(output)  # (batch, seq_len, sequence_input_dim)
        
        # å–æœ€åæ—¶åˆ»
        batch_indices = torch.arange(batch_size, device=device)
        last_indices = (seq_lengths - 1).long()
        user_repr = output[batch_indices, last_indices]  # (batch, sequence_input_dim)
        
        # ==================== 4. ç”¨æˆ·è¡¨å¾ï¼ˆé‡å­ç¼–ç  or ç›´æ¥æŠ•å½±ï¼‰====================
        
        if self.enable_quantum:
            quantum_output = self.quantum_encoder(
                user_repr,
                return_all_interests=True
            )
            user_embed = quantum_output['output']  # (batch, item_embed_dim)
            # â­ diversityç°åœ¨æ˜¯"ç›¸ä¼¼åº¦æƒ©ç½š"ï¼Œç›´æ¥ä½œä¸ºæŸå¤±ï¼ˆè¶Šå°è¶Šå¥½=å…´è¶£è¶Šæ­£äº¤ï¼‰
            if return_loss:
                diversity_loss = quantum_output['metrics']['diversity']
            else:
                diversity_loss = None
        else:
            user_embed = self.user_proj(user_repr)  # (batch, item_embed_dim)
            diversity_loss = None
        
        # å½’ä¸€åŒ–
        user_embed = F.normalize(user_embed, p=2, dim=-1)
        
        # ==================== 5. å› æœæ¨æ–­ï¼ˆå¯é€‰ï¼‰====================
        
        causal_loss = None
        if self.enable_causal and return_loss and target_items is not None and self.enable_disentangled:
            # åªæœ‰å¼€å¯äº†è§£è€¦æ¨¡å—ï¼Œæ‰èƒ½åšå› æœæ¨æ–­ï¼ˆéœ€è¦è§£è€¦çš„ç‰¹å¾ï¼‰
            # éœ€è¦ä»è§£è€¦æ¨¡å—æ”¶é›†æ¯ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾
            # è¿™é‡Œç®€åŒ–ï¼šä½¿ç”¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è§£è€¦ç‰¹å¾
            
            # è·å–æœ€åæ—¶é—´æ­¥çš„è§£è€¦ç‰¹å¾
            last_step_multimodal = {
                'text': text_seq[batch_indices, last_indices, :],
                'image': image_seq[batch_indices, last_indices, :]
            }
            
            # è·å–è§£è€¦ç‰¹å¾ï¼ˆåŒ…å«å®Œæ•´çš„VAEè¾“å‡ºï¼‰
            last_disentangled = self.disentangled_module(
                last_step_multimodal,
                return_loss=False
            )
            
            # æå–éœ€è¦çš„ç‰¹å¾
            z_dict = {
                'emotion': last_disentangled['z_emotion'],
                'aesthetics': last_disentangled['z_aesthetics'],
                'function': last_disentangled['z_context']  # contextä½œä¸ºfunction
            }
            
            mu_dict = {
                'emotion': last_disentangled['modality_disentangled']['text']['emotion']['mu'],
                'aesthetics': last_disentangled['modality_disentangled']['image']['aesthetics']['mu'],
                'function': last_disentangled['context_full']['mu']
            }
            
            logvar_dict = {
                'emotion': last_disentangled['modality_disentangled']['text']['emotion']['logvar'],
                'aesthetics': last_disentangled['modality_disentangled']['image']['aesthetics']['logvar'],
                'function': last_disentangled['context_full']['logvar']
            }
            
            # åˆ›å»ºæ¨èæ‰“åˆ†å‡½æ•°
            def recommendation_head(user_embedding):
                """è®¡ç®—æ¨èå¾—åˆ†"""
                user_embedding_norm = F.normalize(user_embedding, p=2, dim=-1)
                item_emb_norm = F.normalize(self.item_embedding.weight, p=2, dim=-1)
                scores = torch.matmul(user_embedding_norm, item_emb_norm.T)
                scores = scores / self.temperature + self.item_bias
                return scores
            
            # è·å–item embeddingï¼ˆç”¨äºæ‹¼æ¥ï¼‰
            last_item_embeds = item_embeds[batch_indices, last_indices, :]
            
            # è°ƒç”¨å› æœæ¨æ–­æ¨¡å—
            if self.enable_quantum:
                # ä½¿ç”¨é‡å­ç¼–ç å™¨
                causal_output = self.causal_module.scm(
                    z_dict=z_dict,
                    mu_dict=mu_dict,
                    logvar_dict=logvar_dict,
                    quantum_encoder=self.quantum_encoder,
                    recommendation_head=recommendation_head,
                    target_items=target_items,
                    candidate_items=candidate_items,
                    item_embedding=last_item_embeds
                )
            else:
                # ä¸ä½¿ç”¨é‡å­ç¼–ç å™¨ï¼Œç”¨ç®€å•çš„æŠ•å½±
                class SimpleProjector(nn.Module):
                    def __init__(self, proj):
                        super().__init__()
                        self.proj = proj
                    def __call__(self, x):
                        return {'output': self.proj(x)}
                
                simple_encoder = SimpleProjector(self.user_proj)
                
                causal_output = self.causal_module.scm(
                    z_dict=z_dict,
                    mu_dict=mu_dict,
                    logvar_dict=logvar_dict,
                    quantum_encoder=simple_encoder,
                    recommendation_head=recommendation_head,
                    target_items=target_items,
                    candidate_items=candidate_items,
                    item_embedding=last_item_embeds
                )
            
            causal_loss = causal_output['causal_loss']
        elif self.enable_causal and not self.enable_disentangled:
            # å› æœæ¨æ–­éœ€è¦è§£è€¦ç‰¹å¾ï¼Œå¦‚æœæ²¡æœ‰å¼€å¯è§£è€¦ï¼ŒæŸå¤±ä¸º0
            causal_loss = torch.tensor(0.0, device=device)
        else:
            causal_loss = None
        
        # ==================== 6. æ‰“åˆ† ====================
        
        item_emb_norm = F.normalize(self.item_embedding.weight, p=2, dim=-1)
        
        if candidate_items is not None:
            # å€™é€‰æ¨¡å¼
            candidate_emb = item_emb_norm[candidate_items]  # (batch, num_cand, dim)
            logits = torch.bmm(
                candidate_emb,
                user_embed.unsqueeze(-1)
            ).squeeze(-1)  # (batch, num_cand)
            logits = logits / self.temperature + self.item_bias[candidate_items]
        else:
            # å…¨åº“æ¨¡å¼
            logits = torch.matmul(user_embed, item_emb_norm.T)  # (batch, num_items+1)
            logits = logits / self.temperature + self.item_bias
            logits[:, 0] = -1e9  # mask padding
        
        results = {
            'recommendation_logits': logits,
            'user_representation': user_embed
        }
        
        # ==================== 7. æŸå¤±è®¡ç®— ====================
        
        if return_loss and target_items is not None and candidate_items is not None:
            # BPRæŸå¤±
            pos_scores = logits[:, 0]
            neg_scores = logits[:, 1:]
            bpr_loss = self.bpr_loss_fn(pos_scores, neg_scores)
            
            # æ€»æŸå¤±
            total_loss = bpr_loss
            
            if recon_loss is not None:
                total_loss = total_loss + self.alpha_recon * recon_loss
            
            if diversity_loss is not None:
                total_loss = total_loss + self.alpha_diversity * diversity_loss
            
            if causal_loss is not None:
                total_loss = total_loss + self.alpha_causal * causal_loss
            
            results['loss'] = total_loss
            results['bpr_loss'] = bpr_loss
            results['recon_loss'] = recon_loss if recon_loss is not None else torch.tensor(0.0)
            results['diversity_loss'] = diversity_loss if diversity_loss is not None else torch.tensor(0.0)
            results['causal_loss'] = causal_loss if causal_loss is not None else torch.tensor(0.0)
        
        return results


def test_progressive_model():
    """æµ‹è¯•ä¸åŒé…ç½®"""
    print("="*80)
    print("æµ‹è¯•æ¸è¿›å¼æ¨¡å‹")
    print("="*80)
    
    batch_size = 4
    seq_len = 10
    num_items = 100
    
    # æ¨¡æ‹Ÿæ•°æ®
    item_ids = torch.randint(1, num_items, (batch_size, seq_len))
    multimodal_features = {
        'text': torch.randn(batch_size, seq_len, 768),
        'image': torch.randn(batch_size, seq_len, 2048)
    }
    seq_lengths = torch.tensor([10, 8, 6, 9])
    target_items = torch.randint(1, num_items, (batch_size,))
    candidate_items = torch.randint(1, num_items, (batch_size, 5))
    candidate_items[:, 0] = target_items  # ç¬¬ä¸€ä¸ªæ˜¯æ­£æ ·æœ¬
    
    configs = [
        ("Stage 0: Baseline", False, False, False),
        ("Stage 1: +è§£è€¦", True, False, False),
        ("Stage 2: +é‡å­", True, True, False),
        ("Stage 3: å®Œæ•´", True, True, True),
    ]
    
    for name, dis, quan, cau in configs:
        print(f"\n{'='*80}")
        print(f"æµ‹è¯• {name}")
        print(f"{'='*80}")
        
        model = ProgressiveMultimodalRecommender(
            num_items=num_items,
            enable_disentangled=dis,
            enable_quantum=quan,
            enable_causal=cau
        )
        
        outputs = model(
            item_ids=item_ids,
            multimodal_features=multimodal_features,
            seq_lengths=seq_lengths,
            target_items=target_items,
            candidate_items=candidate_items,
            return_loss=True
        )
        
        print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"  - Logits shape: {outputs['recommendation_logits'].shape}")
        
        def to_float(x):
            return x.item() if hasattr(x, 'item') else x
        
        print(f"  - Loss: {to_float(outputs['loss']):.4f}")
        print(f"    â”œâ”€ BPR: {to_float(outputs['bpr_loss']):.4f}")
        print(f"    â”œâ”€ Recon: {to_float(outputs['recon_loss']):.4f}")
        print(f"    â”œâ”€ Diversity: {to_float(outputs['diversity_loss']):.4f}")
        print(f"    â””â”€ Causal: {to_float(outputs['causal_loss']):.4f}")
        
        total_params = sum(p.numel() for p in model.parameters())
        print(f"  - å‚æ•°é‡: {total_params/1e6:.2f}M")
    
    print("\n" + "="*80)
    print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    print("="*80)


if __name__ == '__main__':
    test_progressive_model()

