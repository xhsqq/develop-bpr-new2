# 负采样数量分析

## 数据集信息
- 物品总数: 12,042
- 训练样本: 131,413
- 验证样本: 21,850
- 测试样本: 22,156

## 不同负采样策略对比

### 策略1: 5个负样本（BPR经典）
```
训练集大小: 131,413 × 6 = 788,478 pairs
训练-评估比: 6 vs 12,042 = 1:2,007
内存占用: 低
训练速度: 快
```

**优点**:
- 训练快速
- 内存占用少
- BPR理论上只需要成对比较

**缺点**:
- 训练-评估gap巨大（2000倍）
- 模型可能在简单任务上训练，困难任务上评估
- 容易过拟合到简单的负样本

---

### 策略2: 50个负样本（折中方案）
```
训练集大小: 131,413 × 51 = 6,702,063 pairs
训练-评估比: 51 vs 12,042 = 1:236
内存占用: 中等
训练速度: 中等
```

**优点**:
- gap减少到236倍（vs 2007倍）
- 模型见到更多hard negatives
- 训练更接近评估场景

**缺点**:
- 训练时间增加8-10倍
- 内存占用增加

---

### 策略3: 200个负样本（激进方案）
```
训练集大小: 131,413 × 201 = 26,414,013 pairs
训练-评估比: 201 vs 12,042 = 1:60
内存占用: 高
训练速度: 慢
```

**优点**:
- gap进一步减少（60倍）
- 更接近全库训练

**缺点**:
- 训练时间增加40倍
- 可能导致训练不稳定
- 梯度噪声增大

---

## 实验建议：渐进式测试

### Phase 1: 快速验证（num_negatives=5）
- 目的: 验证模型基本架构是否work
- 训练时间: 最快
- 如果这个都不work，说明模型设计有问题

### Phase 2: 中等负采样（num_negatives=50）
- 目的: 平衡训练效率和性能
- 预期提升: NDCG@10可能提升20-50%
- 推荐作为主要实验设置

### Phase 3: 大量负采样（num_negatives=200）
- 目的: 探索性能上限
- 仅在Phase 2效果好时尝试
- 可能边际收益递减

---

## 文献参考

### 支持少量负采样的论文：
1. **BPR-MF (2009)**: 1-4个负样本
   - "one random negative item per positive"

2. **NCF (2017)**: 4个负样本
   - "we randomly sample 4 negative instances"

3. **SASRec (2018)**: 1个负样本
   - "one negative item sampled uniformly"

### 支持大量负采样的观点：
1. **Sampling-Bias-Corrected Neural Modeling (2019)**
   - 建议使用更多负样本以减少采样偏差

2. **Hard Negative Mining**相关工作
   - 50-100个负样本，选择hard negatives

---

## 我的建议（基于12K items数据集）

### 推荐配置：
```yaml
# 快速实验
num_negatives: 5

# 正式实验（推荐）
num_negatives: 50

# 性能调优
num_negatives: 100-200
```

### 为什么推荐50？
1. Gap从2007倍降到236倍（显著改善）
2. 训练时间可接受（约10倍）
3. 足够的hard negatives让模型学习
4. 在12K物品规模下是合理的折中

---

## 如何判断最优值？

通过实验观察：
1. **如果5→50提升明显** → 继续增加到100
2. **如果5→50提升不明显** → 说明模型设计有问题，不是负采样的锅
3. **如果50→100提升<5%** → 边际收益递减，停在50

---

## 结论

**不存在唯一正确答案**，取决于：
- 数据集规模（12K items → 建议50-100）
- 计算资源（有GPU → 可以多试）
- 任务目标（快速验证 vs 极致性能）

**我的最终建议**：
1. 先用5训练，验证代码无bug
2. 再用50训练，作为baseline
3. 如果50效果好，尝试100
4. 观察50→100的提升是否值得额外训练时间
