"""
æµ‹è¯•æœ€ä¼˜é…ç½®çš„å‚æ•°é‡
éªŒè¯é’ˆå¯¹13ä¸‡æ ·æœ¬çš„å‚æ•°è®¾è®¡æ˜¯å¦åˆç†
"""
import torch
import yaml
from models.multimodal_recommender import MultimodalRecommender


def count_parameters(model):
    """ç»Ÿè®¡æ¨¡å‹å‚æ•°"""
    total = sum(p.numel() for p in model.parameters())
    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    # æŒ‰æ¨¡å—ç»Ÿè®¡
    module_params = {}
    for name, module in model.named_children():
        params = sum(p.numel() for p in module.parameters())
        module_params[name] = params
    
    return total, trainable, module_params


def test_config(config_path, config_name):
    """æµ‹è¯•æŒ‡å®šé…ç½®"""
    print("\n" + "=" * 80)
    print(f"ğŸ“Š æµ‹è¯•é…ç½®: {config_name}")
    print("=" * 80)
    
    # åŠ è½½é…ç½®
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # æ¨¡æ‹Ÿæ•°æ®è§„æ¨¡ (Beautyæ•°æ®é›†)
    num_items = 12042
    num_train_samples = 131413
    
    print(f"æ•°æ®è§„æ¨¡: {num_train_samples:,} è®­ç»ƒæ ·æœ¬, {num_items:,} ç‰©å“\n")
    
    # è¯»å–æ¨¡å‹é…ç½®
    model_config = config['model']
    loss_config = config['loss']
    advanced_config = config.get('advanced', {})
    
    # æ¨¡æ€ç»´åº¦
    modality_dims = model_config['modality_dims']
    
    # æŠ•å½±å±‚ç»´åº¦ï¼ˆå¦‚æœæœ‰ï¼‰
    modality_proj_dims = model_config.get('modality_proj_dims', None)
    
    # å› æœæŸå¤±æƒé‡
    causal_loss_weights = {'magnitude': loss_config.get('causal_weights', {}).get('magnitude', 1.0)}
    
    # åˆ›å»ºæ¨¡å‹
    print("åˆ›å»ºæ¨¡å‹...")
    model = MultimodalRecommender(
        modality_dims=modality_dims,
        modality_proj_dims=modality_proj_dims,
        disentangled_dim=model_config['disentangled_dim'],
        num_disentangled_dims=model_config['num_disentangled_dims'],
        num_interests=model_config['num_interests'],
        quantum_state_dim=model_config['quantum_state_dim'],
        hidden_dim=model_config['hidden_dim'],
        item_embed_dim=model_config['item_embed_dim'],
        num_items=num_items,
        max_seq_length=config['data']['max_seq_length'],
        alpha_recon=loss_config['alpha_recon'],
        alpha_causal=loss_config['alpha_causal'],
        alpha_diversity=loss_config['alpha_diversity'],
        causal_loss_weights=causal_loss_weights,
        num_negatives=advanced_config.get('num_negatives', 100),
        use_quantum_computing=False,
        beta=loss_config.get('beta', 0.05),
        temperature=advanced_config.get('temperature', 0.5),
        num_mc_samples=advanced_config.get('num_mc_samples', 10),
        num_ensembles=advanced_config.get('num_ensembles', 3),
        target_ite=advanced_config.get('target_ite', 0.3),
        dropout=model_config.get('dropout', 0.2)
    )
    
    # ç»Ÿè®¡å‚æ•°
    total_params, trainable_params, module_params = count_parameters(model)
    
    print(f"\nâœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    print(f"æ€»å‚æ•°é‡: {total_params:,} ({total_params/1e6:.2f}M)")
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,} ({trainable_params/1e6:.2f}M)")
    
    # å‚æ•°/æ ·æœ¬æ¯”ï¼ˆä¿®æ­£è®¡ç®—ï¼‰
    ratio = total_params / num_train_samples  # å‚æ•°/æ ·æœ¬
    samples_per_param = num_train_samples / total_params  # æ ·æœ¬/å‚æ•°
    
    print(f"\nğŸ“Š å‚æ•°æ•ˆç‡åˆ†æ:")
    print(f"  å‚æ•°/æ ·æœ¬æ¯”: {ratio:.4f} (å‚æ•°é‡ / æ ·æœ¬æ•°)")
    print(f"  æ ·æœ¬/å‚æ•°æ¯”: {samples_per_param:.2f} (æ¯ä¸ªå‚æ•°æœ‰å¤šå°‘æ ·æœ¬)")
    
    # è¯„ä¼°ï¼ˆåŸºäºæ ·æœ¬/å‚æ•°æ¯”ï¼‰
    if samples_per_param >= 100:
        status = "âœ… ä¼˜ç§€"
        explanation = f"æ¯ä¸ªå‚æ•°æœ‰{samples_per_param:.0f}ä¸ªæ ·æœ¬ï¼Œå……åˆ†è®­ç»ƒ"
    elif samples_per_param >= 50:
        status = "âœ… è‰¯å¥½"
        explanation = f"æ¯ä¸ªå‚æ•°æœ‰{samples_per_param:.0f}ä¸ªæ ·æœ¬ï¼Œè®­ç»ƒå……è¶³"
    elif samples_per_param >= 20:
        status = "âš ï¸  å¯æ¥å—"
        explanation = f"æ¯ä¸ªå‚æ•°æœ‰{samples_per_param:.0f}ä¸ªæ ·æœ¬ï¼Œéœ€æ³¨æ„æ­£åˆ™åŒ–"
    elif samples_per_param >= 10:
        status = "âš ï¸  åå°"
        explanation = f"æ¯ä¸ªå‚æ•°æœ‰{samples_per_param:.0f}ä¸ªæ ·æœ¬ï¼Œéœ€å¼ºæ­£åˆ™åŒ–"
    else:
        status = "ğŸ”´ è¿‡æ‹Ÿåˆé£é™©"
        explanation = f"æ¯ä¸ªå‚æ•°åªæœ‰{samples_per_param:.1f}ä¸ªæ ·æœ¬ï¼Œå®¹æ˜“è¿‡æ‹Ÿåˆ"
    
    print(f"  çŠ¶æ€: {status} - {explanation}")
    
    # æ¨¡å—å‚æ•°åˆ†å¸ƒ
    print(f"\nğŸ“¦ æ¨¡å—å‚æ•°åˆ†å¸ƒ:")
    sorted_modules = sorted(module_params.items(), key=lambda x: x[1], reverse=True)
    for name, params in sorted_modules[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªæœ€å¤§çš„æ¨¡å—
        percentage = params / total_params * 100
        print(f"  {name:30s}: {params:>10,} ({percentage:>5.1f}%)")
    
    # æ˜¾ç¤ºå…³é”®é…ç½®
    print(f"\nğŸ”§ å…³é”®é…ç½®:")
    if modality_proj_dims:
        text_proj = modality_proj_dims.get('text', modality_dims['text'])
        image_proj = modality_proj_dims.get('image', modality_dims['image'])
        print(f"  æŠ•å½±å±‚: Text {modality_dims['text']}â†’{text_proj}, "
              f"Image {modality_dims['image']}â†’{image_proj}")
        
        # è®¡ç®—æŠ•å½±å±‚å‚æ•°
        proj_params = modality_dims['text'] * text_proj + modality_dims['image'] * image_proj
        proj_percentage = (module_params.get('modality_projections', 0) / total_params * 100) if total_params > 0 else 0
        print(f"  æŠ•å½±å±‚å‚æ•°: {proj_params:,} ({proj_percentage:.1f}%)")
    else:
        print(f"  æŠ•å½±å±‚: æœªå¯ç”¨")
    
    print(f"  ItemåµŒå…¥: {model_config['item_embed_dim']}ç»´ "
          f"({num_items * model_config['item_embed_dim']:,}å‚æ•°)")
    print(f"  è§£è€¦ç»´åº¦: {model_config['disentangled_dim']}ç»´ Ã— {model_config['num_disentangled_dims']}")
    print(f"  é‡å­å…´è¶£: {model_config['num_interests']}ä¸ª Ã— {model_config['quantum_state_dim']}ç»´")
    print(f"  éšè—å±‚: {model_config['hidden_dim']}ç»´")
    print(f"  Dropout: {model_config.get('dropout', 0.2)}")
    
    print("=" * 80)
    
    return {
        'total_params': total_params,
        'ratio': ratio,
        'samples_per_param': samples_per_param,
        'status': status
    }


def main():
    """æµ‹è¯•æ‰€æœ‰é…ç½®"""
    print("\n" + "=" * 80)
    print("ğŸ¯ å¤šæ¨¡æ€æ¨èç³»ç»Ÿ - å‚æ•°é…ç½®å¯¹æ¯”åˆ†æ")
    print("=" * 80)
    
    configs = [
        ('config_optimal.yaml', 'æœ€ä¼˜é…ç½® (æ–°è®¾è®¡)'),
        ('config_balanced.yaml', 'å¹³è¡¡é…ç½®'),
        ('config.yaml', 'å½“å‰é…ç½®'),
    ]
    
    results = {}
    for config_path, config_name in configs:
        try:
            result = test_config(config_path, config_name)
            results[config_name] = result
        except FileNotFoundError:
            print(f"\nâš ï¸  é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}")
        except Exception as e:
            print(f"\nâŒ æµ‹è¯•å¤±è´¥ ({config_path}): {e}")
            # import traceback
            # traceback.print_exc()
    
    # å¯¹æ¯”æ€»ç»“
    if len(results) > 1:
        print("\n" + "=" * 80)
        print("ğŸ“Š é…ç½®å¯¹æ¯”æ€»ç»“")
        print("=" * 80)
        print(f"{'é…ç½®åç§°':<25} {'å‚æ•°é‡(M)':<12} {'æ ·æœ¬/å‚æ•°':<12} {'çŠ¶æ€':<20}")
        print("-" * 80)
        for name, result in results.items():
            print(f"{name:<25} {result['total_params']/1e6:<12.2f} "
                  f"{result['samples_per_param']:<12.1f} {result['status']:<20}")
        
        # æ¨è
        print("\nğŸ’¡ æ¨èé…ç½®:")
        best_config = max(results.items(), key=lambda x: x[1]['samples_per_param'])
        print(f"  â†’ {best_config[0]}")
        print(f"    ç†ç”±: æ ·æœ¬/å‚æ•°æ¯”æœ€é«˜ ({best_config[1]['samples_per_param']:.1f})ï¼Œè®­ç»ƒæœ€å……åˆ†")
    
    print("\n" + "=" * 80)
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("=" * 80)


if __name__ == '__main__':
    main()

