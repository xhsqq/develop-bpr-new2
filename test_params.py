"""
æµ‹è¯•æ¨¡å‹å‚æ•°é‡å’Œæ ·æœ¬æ¯”ä¾‹
"""
import torch
import yaml
from models.multimodal_recommender import MultimodalRecommender
from data.dataloader import get_dataloaders

def count_parameters(model):
    """ç»Ÿè®¡æ¨¡å‹å‚æ•°"""
    total = sum(p.numel() for p in model.parameters())
    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    # æŒ‰æ¨¡å—ç»Ÿè®¡
    module_params = {}
    for name, module in model.named_children():
        params = sum(p.numel() for p in module.parameters())
        module_params[name] = params
    
    return total, trainable, module_params

def main():
    # åŠ è½½é…ç½®
    with open('config.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    print("=" * 80)
    print("ğŸ“Š åŠ è½½æ•°æ®ç»Ÿè®¡è®­ç»ƒæ ·æœ¬æ•°")
    print("=" * 80)
    
    # åŠ è½½æ•°æ®
    train_loader, valid_loader, test_loader, dataset_info = get_dataloaders(
        category=config['data']['category'],
        batch_size=config['training']['batch_size'],
        num_workers=config['data']['num_workers'],
        max_seq_length=config['data']['max_seq_length'],
        num_negatives=config['advanced']['num_negatives']
    )
    
    num_users = dataset_info['num_users']
    num_items = dataset_info['num_items']
    
    num_train_samples = len(train_loader.dataset)
    num_valid_samples = len(valid_loader.dataset)
    num_test_samples = len(test_loader.dataset)
    
    print(f"âœ… è®­ç»ƒæ ·æœ¬æ•°: {num_train_samples:,}")
    print(f"âœ… éªŒè¯æ ·æœ¬æ•°: {num_valid_samples:,}")
    print(f"âœ… æµ‹è¯•æ ·æœ¬æ•°: {num_test_samples:,}")
    print(f"âœ… ç”¨æˆ·æ•°: {num_users:,}")
    print(f"âœ… ç‰©å“æ•°: {num_items:,}")
    print()
    
    print("=" * 80)
    print("ğŸ”§ åˆ›å»ºæ¨¡å‹å¹¶ç»Ÿè®¡å‚æ•°é‡")
    print("=" * 80)
    
    # åˆ›å»ºæ¨¡å‹ï¼ˆç®€åŒ–ç‰ˆï¼Œä»…ç”¨äºç»Ÿè®¡å‚æ•°ï¼‰
    model_config = config['model']
    loss_config = config['loss']
    
    # å› æœæŸå¤±æƒé‡
    causal_loss_weights = {
        'magnitude': loss_config['causal_weights']['magnitude']
    }
    
    model = MultimodalRecommender(
        modality_dims=model_config['modality_dims'],
        disentangled_dim=model_config['disentangled_dim'],
        num_disentangled_dims=model_config['num_disentangled_dims'],
        num_interests=model_config['num_interests'],
        quantum_state_dim=model_config['quantum_state_dim'],
        hidden_dim=model_config['hidden_dim'],
        item_embed_dim=model_config['item_embed_dim'],
        num_items=num_items,
        max_seq_length=config['data']['max_seq_length'],
        alpha_recon=loss_config['alpha_recon'],
        alpha_causal=loss_config['alpha_causal'],
        alpha_diversity=loss_config['alpha_diversity'],
        causal_loss_weights=causal_loss_weights,
        num_negatives=config['advanced']['num_negatives'],
        use_quantum_computing=False,
        beta=loss_config['beta'],
        temperature=config['advanced']['temperature'],
        num_mc_samples=config['advanced']['num_mc_samples'],
        num_ensembles=config['advanced']['num_ensembles'],
        target_ite=config['advanced']['target_ite']
    )
    
    total_params, trainable_params, module_params = count_parameters(model)
    
    print(f"\nğŸ“ˆ æ€»å‚æ•°é‡: {total_params:,} ({total_params/1e6:.2f}M)")
    print(f"ğŸ“ˆ å¯è®­ç»ƒå‚æ•°: {trainable_params:,} ({trainable_params/1e6:.2f}M)")
    print()
    
    print("=" * 80)
    print("ğŸ“¦ å„æ¨¡å—å‚æ•°é‡åˆ†å¸ƒ")
    print("=" * 80)
    sorted_modules = sorted(module_params.items(), key=lambda x: x[1], reverse=True)
    for name, params in sorted_modules:
        percentage = params / total_params * 100
        print(f"  {name:30s}: {params:>10,} ({percentage:>5.1f}%)")
    print()
    
    print("=" * 80)
    print("âš–ï¸ å‚æ•°é‡ vs æ ·æœ¬æ•° æ¯”ä¾‹åˆ†æ")
    print("=" * 80)
    ratio = total_params / num_train_samples
    print(f"  å‚æ•°é‡/è®­ç»ƒæ ·æœ¬ = {total_params:,} / {num_train_samples:,} = {ratio:.2f}")
    print()
    
    # å‚è€ƒæ ‡å‡†
    print("  ğŸ“š ä¸šç•Œå‚è€ƒæ ‡å‡†ï¼š")
    print("  âœ… ä¼˜ç§€ï¼šæ¯ä¸ªå‚æ•° >= 10ä¸ªæ ·æœ¬ (ratio <= 0.1)")
    print("  âš ï¸  å¯æ¥å—ï¼šæ¯ä¸ªå‚æ•° 5-10ä¸ªæ ·æœ¬ (ratio = 0.1-0.2)")
    print("  ğŸ”´ è¿‡æ‹Ÿåˆé£é™©ï¼šæ¯ä¸ªå‚æ•° < 5ä¸ªæ ·æœ¬ (ratio > 0.2)")
    print()
    
    if ratio <= 0.1:
        status = "âœ… ä¼˜ç§€"
    elif ratio <= 0.2:
        status = "âš ï¸ å¯æ¥å—"
    else:
        status = "ğŸ”´ è¿‡æ‹Ÿåˆé£é™©"
    
    print(f"  å½“å‰çŠ¶æ€: {status}")
    print()
    
    # å»ºè®®
    if ratio > 0.2:
        print("=" * 80)
        print("ğŸ’¡ ä¼˜åŒ–å»ºè®®")
        print("=" * 80)
        target_params = int(num_train_samples * 0.1)
        reduction_needed = total_params - target_params
        reduction_pct = reduction_needed / total_params * 100
        
        print(f"  ğŸ¯ ç›®æ ‡å‚æ•°é‡: {target_params:,} ({target_params/1e6:.2f}M)")
        print(f"  ğŸ“‰ éœ€è¦å‡å°‘: {reduction_needed:,} ({reduction_pct:.1f}%)")
        print()
        
        # åˆ†ææœ€å¤§çš„æ¨¡å—
        top_module, top_params = sorted_modules[0]
        print(f"  â­ æœ€å¤§æ¨¡å—: {top_module} ({top_params:,}, {top_params/total_params*100:.1f}%)")
        
        # å¦‚æœæ˜¯item_embedding
        if top_module == 'item_embedding':
            current_dim = config['model']['item_embed_dim']
            target_dim = int(current_dim * (target_params / total_params) ** 0.5)
            target_dim = max(32, (target_dim // 16) * 16)  # å‘ä¸‹å–æ•´åˆ°16çš„å€æ•°
            print(f"  ğŸ’¡ å»ºè®®: item_embed_dim: {current_dim} â†’ {target_dim}")
        
        print()
        print("  ğŸ”§ å…¶ä»–ä¼˜åŒ–æ–¹å‘ï¼š")
        print("  1. æ·»åŠ BERT/ResNetæŠ•å½±é™ç»´å±‚ï¼ˆ768â†’128, 2048â†’256ï¼‰")
        print("  2. è¿›ä¸€æ­¥å‡å° hidden_dimï¼ˆ64â†’32ï¼‰")
        print("  3. å‡å°‘ num_interestsï¼ˆ3â†’2ï¼‰")
        print()
    
    print("=" * 80)
    print("ğŸ” å¤šæ¨¡æ€ç‰¹å¾ç»´åº¦åˆ†æ")
    print("=" * 80)
    text_dim = config['model']['modality_dims']['text']
    image_dim = config['model']['modality_dims']['image']
    print(f"  Text (BERT):   {text_dim} ç»´")
    print(f"  Image (ResNet): {image_dim} ç»´")
    print(f"  æ€»è®¡:          {text_dim + image_dim} ç»´")
    print()
    
    # è®¡ç®—å¤šæ¨¡æ€ç¼–ç å™¨çš„å‚æ•°
    disentangled_params = module_params.get('disentangled_module', 0)
    print(f"  è§£è€¦æ¨¡å—å‚æ•°é‡: {disentangled_params:,} ({disentangled_params/total_params*100:.1f}%)")
    
    # ä¼°ç®—å¦‚æœåŠ æŠ•å½±å±‚èƒ½å‡å°‘å¤šå°‘å‚æ•°
    text_proj_dim = 128
    image_proj_dim = 256
    print()
    print("  ğŸ’¡ å¦‚æœæ·»åŠ æŠ•å½±é™ç»´ï¼š")
    print(f"     Text:  {text_dim} â†’ {text_proj_dim}")
    print(f"     Image: {image_dim} â†’ {image_proj_dim}")
    print(f"     æ€»ç»´åº¦: {text_dim + image_dim} â†’ {text_proj_dim + image_proj_dim}")
    print(f"     ç»´åº¦å‡å°‘: {((text_dim + image_dim) - (text_proj_dim + image_proj_dim)) / (text_dim + image_dim) * 100:.1f}%")
    
    # æŠ•å½±å±‚æ–°å¢å‚æ•°
    proj_params = text_dim * text_proj_dim + image_dim * image_proj_dim
    print(f"     æ–°å¢æŠ•å½±å±‚å‚æ•°: {proj_params:,}")
    
    # è§£è€¦æ¨¡å—èŠ‚çœå‚æ•°ï¼ˆç²—ç•¥ä¼°ç®—ï¼šè¾“å…¥ç»´åº¦å‡å°‘ï¼Œç¼–ç å™¨å‚æ•°å¤§çº¦å‡å°‘ç›¸åŒæ¯”ä¾‹ï¼‰
    dim_ratio = (text_proj_dim + image_proj_dim) / (text_dim + image_dim)
    estimated_savings = disentangled_params * (1 - dim_ratio) - proj_params
    
    if estimated_savings > 0:
        print(f"     é¢„è®¡å‡€èŠ‚çœå‚æ•°: {estimated_savings:,} ({estimated_savings/total_params*100:.1f}%)")
        new_total = total_params - estimated_savings
        new_ratio = new_total / num_train_samples
        print(f"     ä¼˜åŒ–åå‚æ•°é‡: {new_total:,} ({new_total/1e6:.2f}M)")
        print(f"     ä¼˜åŒ–åæ¯”ä¾‹: {new_ratio:.2f}")
    else:
        print(f"     âš ï¸ æŠ•å½±å±‚å¯èƒ½ä¸ä¼šå‡å°‘å‚æ•°ï¼ˆæ–°å¢ > èŠ‚çœï¼‰")
    
    print("=" * 80)

if __name__ == '__main__':
    main()

